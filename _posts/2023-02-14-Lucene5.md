---
author_profile: true
date: 2023-02-27
title: "Apache Lucene 5 (Search Engine)"
categories: 
    - Search
tag: 
    - Lucene
    - SpringBoot
    - RestAPI

# 목차
toc: true  
toc_sticky: true 
# sidebar:
#  nav: "docs"
---

# Apache Lucene 5 (Analyzer)

---

## 1. 분석기란

루씬의 분석기 텍스트 처리는 색인과 검색 과정에서 모두 일어난다.
분석기는 루씬의 핵심기능으로 언어별로 다양한 분석기가 제공된다.
기본 분석기를 이해해야 본인이 원하고자하는 형태로 분석되도록 커스텀 분석기를 생성할 수 있다.
루씬에서의 분석기는 텍스트를 형태소로 만들어 검색에 용이하게 하는 것이다.

### 1-1. 색인 과정에서의 분석기 활용

색인 과정에서 분석은 색인 시 텍스트 데이터를 검색에 용이한 형태로 저장하는 것이다.
즉, 색인 시 addDocument(doc) 의 결과로 추가된 문서 Document에 색인된 각각의 필드를 색인할 분석기 구현체가 호출된다.

#### 데이터 정제

텍스트 분석에 앞서 토큰화 사전 작업으로 HTML마크업, 임의의 패턴(`\t`, `\r` 등), 고정 문자열 세트와 일치하는 텍스트 변형 또는 제거 하는 등 의 작업을 하게 된다.

위와 같은 작업을 하는 데이터 정제는 각 어플리케이션 마다 방식이 다름.

대표적인 정제필터는 `CharFilter` 가 있으며, 토큰 필터와 연결이 가능하며, 토크나이저 앞에 위치한다.
HTMLStripCharFilter는 HTML 구문을 제거하는 역할을 MappingCharFilter는 백스페이스(`\b`), 탭(`\t`), 개행문자(`\n`) 등을 유니코드 문자로 변환한다. 

추가적으로 `StandardFilter`(표준토크나이저)는 공백을 기준으로 단어를 잘라 준다.

소문자로 변경하는 필터는 `lowercase`필터
너무 자주 사용되어 의미 없는 관사 전치사 제거하는 `stopFilter`
단어에서 어간을 추출하는 형태소 분석 필터인 `snowBallFilter` 가 있다.

#### 역색인 구조로 저장

루씬은 데이터 색인(저장) 할 떄 검색 속도를 높이고자 내부에 사전을 만든다.
사전 제작에 앞서 텍스트를 분석하게 되는데 색인 과정에서 분석기가 사용되는 시점은 인덱스에 문서를 추가하는 IndexWriter 객체의 addDocument를 실행할 때 이다.

### 1-2. 검색에서의 분석

```
입력 -> CharFilter -> Tokenizer -> TokenFilter -> 출력
```

토큰 

텍스트를 분할한 결과로 토크나이저를 통해 분할된다. 예를 들어 He likes apples 를 입력으로 하면 토크나이저를 통해 he, likes, apples 의 3단어로 쪼개지고 이를 토큰이라 한다.

토큰 필터 

토큰 필터는 토크나이저로부터 만들어진 토큰을 토큰 필터로 변형해 텀을 생성한다. 여러가지 기능이 있지만 여러 토큰 필터를 사용할 때 주의해야 하는 점은 토큰 필터에 따라 단어(텀)이 변형이 이뤄질 수 있어 순어에 따라 검색 정확도에 차이가 있을 수 있다.

토큰화 종류

- 동사원형화(Stemming) : 동사원형으로 치환한다.(likes -> like) 위와 같은 작업을 통해 like로 검색해도 likes, like 모두 검색되게 된다.
- 불용어필터링(StopWordFiltering) : the, a, and 와 같은 전치사, 관사 등은 검색에서 어떠한 의미도 가지지 않는다. 따라서 이러한 불용어를 제거함으로서 인덱스의 크기 절감, 및 정확도 향상에 도움이된다.
- 텍스트정규화 : 더 정확한 검색을 위해 Accent와 같은 기타문자를 제거한다.
- 동의어 확장 : 상요자가 단어 검색 시 해당 단어의 동의어를 포함한 문서도 함꼐 조회 되도록 토큰에 동의어를 함께 저장한다. 검색 정확도 향상에 도움을 준다.

---

## 2.분석 관련 클래스

문장은 1개 이상의 단어로 이워진다. 루씬은 가장 작은 단위로 문장의 단어를 분석한다.

분석(Analyze)관련 주요 클래스

- Analyzer : 분석관련 추상클래스로 텍스트를 분석한 TokenStream을 만든다.
- CharFilter : 오프셋을 지원하는 Reader의 하위 클래스 
- Tokenizer : 입력된 텍스트를 토큰으로 분해한다.
- TokenFilter : 토큰과 토큰 스트림을 수정한다.
- TokenStream : 토큰화와 토큰 필터의 결과물로 재사용 가능한 객체
- AttributeSource : 텍스트 토큰에 대한 특정 정보를 보유한 객체

### 2.1 TokenStream 클래스 

TokenStream 은 문서의 필드나 쿼리의 토큰을 순서대로 분석하는 객체로, 토큰화 와 토큰 필터 과정에서 생성되고 재사용된다. 
경우에 따라서는 다양한 분석기를 조합해서 사용가능하다.

- TokenStream의 주요 클래스
  - incrementToken() : IndexWriter처럼 TokenStream에서 소비하는 클래스에 의해 사용되며 다음 토큰 스트림으로 이동한다.
  - reset() : incrementToken() 호출 전 토큰스트림을 초기화 한다.
  - close() : 토큰스트림을 닫는다.
  - end() : 마지막 토큰을 소비한 후 다른 소비자가 사용할 수 있게 종료한다.(소비자 주체는 IndexWriter())

### 2.2 AttributeSource 클래스

토큰의 속성 모음으로 `addAttribute(Class attClass)` 로 사용한다.

- 토큰 속성의 목록
  - CharTermAttribute : 토큰의 텍스트
  - OffsetAttribute : 문자로 표시된 토큰의 시작과 끝 오프셋
  - PositionIncrementAttribute : 토큰위치값으로 토큰을 읽으면 값이 증가
  - PositionLenghtAttribute : 토큰이 차지하는 자리의 수
  - PayloadAttribute : 토큰의 페이로드로 인덱스에 각 토큰의 위치가 저장되며 페이로드 기반 쿼리를 사용할 때 Score에 영향을 준다. 
  - TypeAttribute : 토큰의 유형으로 기본은 단어
  - KeywordAttribute : 토큰을 키워드로 표시하는데 사용됨

AttributeSource는 문자열과 함께 메타 정보를 가지고 있다. 메타정보에는 시작점(Offset), 끝지점(End Offset), 토큰의 타입, 위치 증가 값 등이 있다.

![Attribute 동작방식](/assets/images/2023-02-14/lucene3.png){: .align-center}

### 2.3 Tokenizer 클래스 

전체 텍스트를 단어로 분리하는 클래스 

